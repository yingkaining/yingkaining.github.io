---
title: Kaining Ying
author: Kaining Ying
email: "ykn@zjut.edu.cn"
image: "./files/about/ykn.jpg"
google: "https://scholar.google.com/citations?user=Ym36zRwAAAAJ&hl=zh-CN"
github: "https://github.com/yingkaining"

---

<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script type="text/javascript" src="js/hidebib.js"></script>

  <script type="text/javascript" src="js/paper_display.js"></script>

  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Kaining Ying</title>
  <link rel="shortcut icon" href="./files/about/favicon.ico">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

  <meta name="author" content="Kaining Ying">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <!-- <link rel="icon" type="image/png" href="images/JHU_icon.jpg"> -->
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:70%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Kaining Ying</name>
                  </p>
                  Kaining is a Master student of College of Computer Science and Technology, Zhejiang University of
                  Technology, advised by Dr. <a href="https://zhwaang.github.io/"> Zhenhua Wang</a>. </p>
                  <p> He got Bachelor degree from the Zhejiang University of Technology in 2021.
                  <p> His research interests include computer vision and deep learning, particularly focusing on
                    Instance-level tasks such as Object Detection, Instance Segmentation and Human Interaction
                    Understanding.</p>
                  <p>
                    <b><em>" Only in silence the word, only in dark the light, only in dying life: bright the hawk's flight on the empty sky "
                    â€” Ursula K. Le Guin (A Wizard of Earthsea)</em> </b>
                  </p>
                  
                  

                  <p style="text-align:center">
                    <a href="mailto:ykn@zjut.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="./files/about/resume.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=Ym36zRwAAAAJ&hl=zh-CN">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/yingkaining">Github</a> &nbsp/&nbsp
                    <a href="./files/about/bio.txt">Bio</a>


                  </p>
                </td>
                <td style="padding:2.5%;width:300%;max-width:300%">
                  <a href="files/about/ykn.jpg"><img style="width:110%;max-width:110%"
                      alt="profile photo" src="files/about/ykn.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <heading>Recent News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <ul>
                      <li> <b>[2022/4/28]</b> Our paper MMGraph was accepted by <b>TNNLS 2022</b>. </li>
                      <li> <b>[2022/1/22]</b> Our paper ISDA was accepted by <b>ICASSP 2022</b>. </li>
                      <li> <b>[2020/6/22]</b> Our paper RWMF was accepted by <b>ICPR 2020</b>.</li>

                    </ul>
        </td>
      </tr>
    </tbody>
  </table>
  <hr>



  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Publications</heading>
        </td>
      </tr>
    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody id="paper">
      
      <tr bgcolor="#ffffff">
        <td style="padding:20px;width:35%;vertical-align:middle">
          <img src='files/papers/images/mmgraph.png' width="250"></div>
        </td>
        <td width="75%" valign="middle">
          <p>
            <a href="./files/papers/pdf/mmgraph.pdf">Self-supervised Enhancement for Named Entity Disambiguation via Multimodal Graph Convolution</a> &nbsp&nbsp

            <br>
            Pengfei Zhou*, <b>Kaining Ying*</b>, Zhenhua Wang, Dongyan Guo, Cong Bai
            <br>
            <em>TNNLS2022 (* Equal contribution)</em> ,
            <br>
            <font color="black"> We present MMGraph, which uses multimodal graph convolution to aggregate visual and contextual language information for accurate entity disambiguation for short texts, and a self-supervised simple triplet network (SimTri) that can learn useful representations in multimodal unlabeled data to enhance the effectiveness of NED models.<br>
              <a href="https://github.com/LanceZPF/NNED_MMGraph">project page</a> 
              <!-- <a href="data/xie2020advprop.bib">bibtex</a> <br> -->
            </font>
            <br>

        </td>
      </tr>


      <tr bgcolor="#ffffff">
        <td style="padding:20px;width:35%;vertical-align:middle">
          <img src='files/papers/images/isda.png' width="250"></div>
        </td>
        <td width="75%" valign="middle">
          <p>
            <a href="./files/papers/pdf/isda.pdf">ISDA: Position-Aware Instance Segmentation with Deformable Attention</a> &nbsp&nbsp

            <br>
            <b>Kaining Ying*</b>, Zhenhua Wang, Cong Bai, Pengfei Zhou
            <br>
            <em>ICASSP2022</em>,
            <br>
            <font color="black">We present a novel end-to-end Instance Segmentation framework based on Transformer and
              get 38.7 mAP with ResNet-50 on MS COCO test-dev.<br>
              <a href="https://arxiv.org/abs/2202.12251">arxiv</a> /
              <a href="https://github.com/yingkaining/isda">project page</a> /
              <a href="./files/papers/bib/ying2022isda.bib">bibtex</a> <br>
            </font>
            <br>

        </td>
      </tr>
      <!--xie2020advprop-->




      <tr bgcolor="#ffffff">
        <td style="padding:20px;width:35%;vertical-align:middle">
          <img src='files/papers/images/rwmf.png' width="250"></div>
        </td>
        <td width="75%" valign="middle">
          <p>
            <a href="./files/papers/pdf/rwmf.pdf" style="font-size:18px;">RWMF: A Real-World Multimodal Foodlog Database
            </a> &nbsp&nbsp

            <!-- <a herf="images/sepc.pdf">
                    <papertitle>[1] Scale-equalizing Pyramid Convolution for object detection  </papertitle>
                  </a> -->
            <br>

            Pengfei Zhou, Cong Bai, <b>Kaining Ying</b>, Jie Xia, Lixin Huang
            <br>
            <em>ICPR2020</em>,
            <br>
            <font color="black">We establish a real-world foodlog database using various methods such as filter, cluster and graph convolutional network. This database is built based on real-world lifelog and medical data, which is named as Real-World Multimodal Foodlog (RWMF).  <br>
              <!-- <a href="https://arxiv.org/abs/2202.12251">arxiv</a> / -->
              <!-- <a href="https://github.com/yingkaining/isda">project page</a> / -->
              <a href="./files/papers/bib/zhou2021rwmf.bib">bibtex</a> <br>
            </font>
            <br>
          </p>

        </td>
      </tr>
      <!--xie2020advprop-->


    </tbody>
  </table>


  <hr>


  <!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
  <!--          <tr>-->
  <!--          <td style="padding:10px;width:100%;vertical-align:middle">-->
  <!--            <heading>Project</heading>-->
  <!--          </td>-->
  <!--        </tr>-->
  <!--      </tbody></table>-->
  <!--      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->



  <!--      <tr bgcolor="#ffffff">-->
  <!--          <td style="padding:20px;width:35%;vertical-align:middle">-->
  <!--              <img src='images/kitchen.png' width="200"></div>-->
  <!--          </td>-->
  <!--          <td width="75%" valign="middle">-->
  <!--              <p>-->
  <!--                <br>-->
  <!--                <b> <papertitle>Sense Kitchen</papertitle> </b>-->

  <!--              </a>-->

  <!--              <br>-->
  <!--              <font color="black"> We  built a detector to detects anomaly behavior of chiefs in kitchens. Algorithmic solution is composed by two phases: object detection phase  which detects human heads and body with high recall and classification phase which classifys if the behavior is anomalous.-->
  <!--                We reproduced the   <a href="https://arxiv.org/abs/1903.00621">FSAF</a> and combined it with  <a href="https://arxiv.org/abs/1909.02466"> FreeAnchor</a> to  better deal with occlusion case and the imbalace of positive samples of objects with different sacles.</font>-->
  <!--              <br>-->
  <!--              </p>-->
  <!--              &lt;!&ndash; <div class="paper" id="xie2020advprop">-->
  <!--                  <a href="https://arxiv.org/pdf/1911.09665.pdf">arxiv</a> /-->
  <!--                  <a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet">project page</a> /-->
  <!--                  <a href="https://medium.com/syncedreview/google-johns-hopkins-university-can-adversarial-examples-improve-image-recognition-bcb7254e2d8">press</a> /-->
  <!--                  <a href="https://www.youtube.com/watch?v=KTCztkNJm50">video</a> /-->
  <!--                  <a href="data/xie2020advprop.bib">bibtex</a>-->
  <!--              </div> &ndash;&gt;-->
  <!--          </td>-->
  <!--      </tr> &lt;!&ndash;xie2020advprop&ndash;&gt;-->

  <!--      <tr bgcolor="#ffffff">-->
  <!--          <td style="padding:20px;width:30%;vertical-align:middle">-->
  <!--              <img src='images/radar.png' width="200"ï¼Œ height= "150" >  </div>-->
  <!--          </td>-->
  <!--          <td width="75%" valign="middle">-->
  <!--              <p>-->
  <!--                <b>               <papertitle>Sense Radar</papertitle> </b>-->
  <!--              </a>-->

  <!--              <br>-->
  <!--              <font color="black">-->
  <!--                This was originally a problem of image classification. The requirement was to distinguish whether there were guns and dangerous objects in the image.-->
  <!--                But turning it into a detection problem made network easier to learn.-->
  <!--                  .</font>-->
  <!--              <br>-->
  <!--              </p>-->
  <!--              &lt;!&ndash; <div class="paper" id="xie2020advprop">-->
  <!--                  <a href="https://arxiv.org/pdf/1911.09665.pdf">arxiv</a> /-->
  <!--                  <a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet">project page</a> /-->
  <!--                  <a href="https://medium.com/syncedreview/google-johns-hopkins-university-can-adversarial-examples-improve-image-recognition-bcb7254e2d8">press</a> /-->
  <!--                  <a href="https://www.youtube.com/watch?v=KTCztkNJm50">video</a> /-->
  <!--                  <a href="data/xie2020advprop.bib">bibtex</a>-->
  <!--              </div> &ndash;&gt;-->
  <!--          </td>-->
  <!--      </tr> &lt;!&ndash;xie2020advprop&ndash;&gt;-->



  <!--      <tr bgcolor="#ffffff">-->
  <!--        <td style="padding:20px;width:30%;vertical-align:middle">-->
  <!--            <img src='images/person.png' width="200"ï¼Œ height= "150" >  </div>-->
  <!--        </td>-->
  <!--        <td width="75%" valign="middle">-->
  <!--            <p>-->
  <!--              <b>               <papertitle>Person Detector(In process)</papertitle> </b>-->
  <!--            </a>-->

  <!--            <br>-->
  <!--            <font color="black">-->
  <!--              In order to provide an excellent pre-trained model for various human or face related tasks,-->
  <!--              I have collected many open source datasets related to body and face to train a high performance detector.-->
  <!--              In this project, I implemented the algorithm called <a href=https://zhuanlan.zhihu.com/p/73162940?utm_source=wechat_session&utm_medium=social&utm_oi=659344454985584640> Groupsoftmax</a>,-->
  <!--              which could union data sets of different annotation categories . Thanks to Luobe Chen.-->
  <!--               I've also learned some techniques for dealing with crowded people.</font>-->
  <!--            <br>-->
  <!--            </p>-->
  <!--            &lt;!&ndash; <div class="paper" id="xie2020advprop">-->
  <!--                <a href="https://arxiv.org/pdf/1911.09665.pdf">arxiv</a> /-->
  <!--                <a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet">project page</a> /-->
  <!--                <a href="https://medium.com/syncedreview/google-johns-hopkins-university-can-adversarial-examples-improve-image-recognition-bcb7254e2d8">press</a> /-->
  <!--                <a href="https://www.youtube.com/watch?v=KTCztkNJm50">video</a> /-->
  <!--                <a href="data/xie2020advprop.bib">bibtex</a>-->
  <!--            </div> &ndash;&gt;-->
  <!--        </td>-->
  <!--    </tr> &lt;!&ndash;xie2020advprop&ndash;&gt;-->




  <!--    </tbody></table>-->
  <!--    <hr>-->



  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td width=30% align="center">
          <script type="text/javascript" id="clustrmaps"
            src="//cdn.clustrmaps.com/map_v2.js?d=YhKG6U66qGxhpkw9wNq2inR7zEgWsQgm_B10AAnjACw&cl=ffffff&w=a"></script>
        </td>
        <td style="padding:10px">
          <br>
          <p style="text-align:right;">Stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>

  <script xml:space="preserve" language="JavaScript">
    hideallbibs();
  </script>


  Google Analytics -->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-131560165-1', 'auto');
    ga('send', 'pageview');
  </script>


  <!-- End Google Analytics -->



</body>

</html>